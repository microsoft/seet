{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data For Analysis of Glint Visibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook generates data for analysis of glint visibility.\n",
    "Generation of 100 combined user-device samples x two eyes x 20 gaze directions,\n",
    "i.e., 4,000 individual samples, takes about 25-40 min on a beefy machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import datetime\n",
    "import seet\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import torch\n",
    "import pandas\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import utils\n",
    "\n",
    "dropdown_widget, text_widget = utils.get_experiment_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_for_visibility_analysis(scene_sampler, gaze_grid=[5, 4]):\n",
    "    \"\"\"generate_data_for_visibility_analysis.\n",
    "\n",
    "    Generate data for visibility analysis.\n",
    "\n",
    "    Args:\n",
    "        gaze_grid (list, optional): size of gaze direction grid on which to\n",
    "        sample the gaze directions. First element is the number of\n",
    "        horizontal samples, second element is the number of vertical\n",
    "        samples. Defaults to [5, 4].\n",
    "    \"\"\"\n",
    "\n",
    "    # We want to collect data about LED visibility, working distance, eye\n",
    "    # clipping, gaze direction, eye relief.\n",
    "\n",
    "    #######################################################################\n",
    "    # Device-only data\n",
    "    header_subsystem = [\"Subsystem\", ]\n",
    "    header_grid_angle = [\"Horiz. angle\", \"Vert. angle\"]\n",
    "    # This assumes that the subsystems have the same number of LEDs.\n",
    "    num_leds = scene_sampler.scene.device.subsystems[0].led_set.num\n",
    "    header_LEDs = [\"LED {:02d}\".format(i) for i in range(1, num_leds + 1)]\n",
    "\n",
    "    #######################################################################\n",
    "    # Device + user data.\n",
    "    header_camera_center_in_pupil = \\\n",
    "        [\n",
    "            \"Camera center in pupil {:s}\".format(ax)\n",
    "            for ax in [\"x\", \"y\", \"z\"]\n",
    "        ]\n",
    "    header_delta_eye_relief = [\"Delta eye relief\", ]\n",
    "    header_scene_index = [\"Scene index\", ]\n",
    "\n",
    "    #######################################################################\n",
    "    # User-only data.\n",
    "    header_gaze_direction = \\\n",
    "        [\"Gaze {:s}\".format(ax) for ax in [\"x\", \"y\", \"z\"]]\n",
    "    header_IPD = [\"IPD\", ]\n",
    "\n",
    "    #######################################################################\n",
    "    # Putting it all together\n",
    "    header = \\\n",
    "        header_subsystem + \\\n",
    "        header_grid_angle + \\\n",
    "        header_LEDs + \\\n",
    "        header_camera_center_in_pupil + \\\n",
    "        header_delta_eye_relief + \\\n",
    "        header_scene_index + \\\n",
    "        header_gaze_direction + \\\n",
    "        header_IPD\n",
    "\n",
    "    num_subsystems = len(scene_sampler.scene.device.subsystems)\n",
    "    data = []\n",
    "    for scene_index, et_scene in enumerate(scene_sampler.generate_samples()):\n",
    "        for subsystem_index in range(num_subsystems):\n",
    "            ###############################################################\n",
    "            # Device-only data.\n",
    "            # Subsystem data.\n",
    "            row_subsystem = [subsystem_index, ]\n",
    "\n",
    "            # Grid angle data.\n",
    "            if gaze_grid[0] != 1 or gaze_grid[1] != 1:\n",
    "                fov_range_deg = scene_sampler.scene.device.display_fov / 2\n",
    "                h_fov_range_deg = \\\n",
    "                    torch.linspace(\n",
    "                        -fov_range_deg[0], fov_range_deg[0], gaze_grid[0]\n",
    "                    )\n",
    "                v_fov_range_deg = \\\n",
    "                    torch.linspace(\n",
    "                        -fov_range_deg[1], fov_range_deg[1], gaze_grid[1]\n",
    "                    )\n",
    "                rotate = True\n",
    "            else:\n",
    "                h_fov_range_deg = torch.zeros(1)\n",
    "                v_fov_range_deg = torch.zeros(1)\n",
    "                rotate = False\n",
    "\n",
    "            subsystem = et_scene.device.subsystems[subsystem_index]\n",
    "\n",
    "            camera_index = 0  # In the future, we may have stereo.\n",
    "            camera = subsystem.cameras[camera_index]\n",
    "\n",
    "            eye = et_scene.user.eyes[subsystem_index]\n",
    "\n",
    "            for hi in range(gaze_grid[0]):\n",
    "                for vi in range(gaze_grid[1]):\n",
    "                    # Rotate the eye if required.\n",
    "                    if rotate:\n",
    "                        angles_deg = \\\n",
    "                            torch.stack(\n",
    "                                (h_fov_range_deg[hi], v_fov_range_deg[vi])\n",
    "                            )\n",
    "                        eye.rotate_from_gaze_angles_inParent(angles_deg)\n",
    "                    else:\n",
    "                        angles_deg = torch.zeros(2)\n",
    "\n",
    "                    row_grid_angle = \\\n",
    "                        [*angles_deg.clone().detach().numpy()]\n",
    "\n",
    "                    #######################################################\n",
    "                    # Device plus user data.\n",
    "                    # Scene (device + user) index.\n",
    "\n",
    "                    # LED-visibility data.\n",
    "                    glints_inCamera = \\\n",
    "                        et_scene.generate_glints_inOther(\n",
    "                            other_node=camera,\n",
    "                            subsystem_index=subsystem_index,\n",
    "                            camera_index=camera_index\n",
    "                        )\n",
    "\n",
    "                    row_LEDs = \\\n",
    "                        [int(g is not None) for g in glints_inCamera]\n",
    "\n",
    "                    # Camera center in pupil.\n",
    "                    transform_toPupil_fromCamera = \\\n",
    "                        camera.get_transform_toOther_fromSelf(eye.pupil)\n",
    "                    optical_center_in_pupil = \\\n",
    "                        transform_toPupil_fromCamera.transform(\n",
    "                            torch.zeros(3)\n",
    "                        )\n",
    "                    row_camera_center_in_pupil = \\\n",
    "                        [*optical_center_in_pupil.clone().detach().numpy()]\n",
    "\n",
    "                    # Eye-relief data.\n",
    "                    eye_relief_plane = subsystem.eye_relief_plane\n",
    "                    cornea_apex_inPlane = \\\n",
    "                        eye.get_cornea_apex_inOther(eye_relief_plane)\n",
    "\n",
    "                    delta_eye_relief = \\\n",
    "                        -1 * eye_relief_plane.\\\n",
    "                        compute_signed_distance_to_point_inPlane(\n",
    "                            cornea_apex_inPlane\n",
    "                        ).clone().detach().numpy()\n",
    "\n",
    "                    row_delta_eye_relief = [delta_eye_relief, ]\n",
    "\n",
    "                    # Keeping track of the samples.\n",
    "                    row_scene_index = [scene_index, ]\n",
    "\n",
    "                    #######################################################\n",
    "                    # User-only data.\n",
    "                    # Gaze-direction data.\n",
    "                    gaze_direction_inScene = \\\n",
    "                        eye.get_gaze_direction_inOther(et_scene)\n",
    "                    row_gaze_direction = \\\n",
    "                        [*gaze_direction_inScene.clone().detach().numpy()]\n",
    "\n",
    "                    # IPD data.\n",
    "                    IPD_data = et_scene.user.compute_IPD()\n",
    "                    row_IPD = [IPD_data.clone().detach().numpy(), ]\n",
    "\n",
    "                    #######################################################\n",
    "                    # Putting it all together.\n",
    "                    row = \\\n",
    "                        row_subsystem + \\\n",
    "                        row_grid_angle + \\\n",
    "                        row_LEDs + \\\n",
    "                        row_camera_center_in_pupil + \\\n",
    "                        row_delta_eye_relief + \\\n",
    "                        row_scene_index + \\\n",
    "                        row_gaze_direction + \\\n",
    "                        row_IPD\n",
    "\n",
    "                    data = data + [row, ]\n",
    "\n",
    "                    if rotate:\n",
    "                        eye.unrotate_from_gaze_angles_inParent(angles_deg)\n",
    "\n",
    "    return pandas.DataFrame(data, columns=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_file_name, \\\n",
    "    sampler_file_name = \\\n",
    "    utils.get_configuration_files(dropdown_widget.value)\n",
    "\n",
    "# print(\"Scene generated using \" + scene_file_name + \" configuration file.\")\n",
    "et_scene = seet.scene.SceneModel(parameter_file_name=scene_file_name)\n",
    "\n",
    "print(\"Sampling parameters from \" + sampler_file_name + \" configuration file.\")\n",
    "scene_sampler = seet.sampler.SceneSampler(\n",
    "    et_scene, num_samples=100, parameter_file_name=sampler_file_name)\n",
    "\n",
    "df = generate_data_for_visibility_analysis(scene_sampler)\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "prefix = now.strftime(\"%Y-%m-%d @ %H-%M-%S.%f\")\n",
    "results_path = text_widget.value\n",
    "os.makedirs(results_path, exist_ok=True)\n",
    "path_prefix = os.path.join(results_path, prefix)\n",
    "\n",
    "df_name = path_prefix + \" data_frame.pkl\"\n",
    "with open(df_name, 'wb') as file_stream:\n",
    "    pickle.dump(df, file_stream)\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SEET_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
